{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch._C' has no attribute '_cuda_setDevice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bz/yv6zpqcs0vgf1wt80wfp36t40000gn/T/ipykernel_30646/2088804417.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# % matplotlib inline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;31m# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/FACT/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mset_device\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_setDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch._C' has no attribute '_cuda_setDevice'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch import optim, nn\n",
    "from torchvision import models, transforms\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "\n",
    "import time\n",
    "\n",
    "from transformers import BertModel\n",
    "from transformers import AdamW\n",
    "\n",
    "# from tqdm.auto import tqdm\n",
    "from tqdm import tqdm,trange \n",
    "# from tqdm import trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import  mean_absolute_error\n",
    "from transformers.optimization import Adafactor\n",
    "# from tabulate import tabulate\n",
    "import os, sys\n",
    "sys.path.append('/path-to/early-stopping-pytorch')\n",
    "from pytorchtools import EarlyStopping\n",
    "import glob\n",
    "\n",
    "import math\n",
    "# % matplotlib inline\n",
    "import os\n",
    "torch.cuda.set_device(1)\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "from transformers.utils import logging\n",
    "logging.set_verbosity(40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[4]:\n",
    "\n",
    "\n",
    "from transformers import ViTFeatureExtractor, ViTModel\n",
    "from transformers import DebertaV2Tokenizer, DebertaV2ForSequenceClassification\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers.modeling_outputs import BaseModelOutput\n",
    "deBERTatokenizer = DebertaV2Tokenizer.from_pretrained(\"microsoft/deberta-v2-xlarge\")\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "# --T5\n",
    "T5tokenizer = T5Tokenizer.from_pretrained(\"t5-large\")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# n_gpu = torch.cuda.device_count()\n",
    "# torch.cuda.get_device_name(0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "# Default dataset files\n",
    "# import pandas as pd\n",
    "data_dir = '/path-to/images'\n",
    "train_path = '/path-to/hvvexp_train.csv'\n",
    "dev_path = '/path-to/hvvexp_val.csv'\n",
    "test_path = '/path-to/hvvexp_test.csv'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# T5 decoder\n",
    "class HarmemeMemesDatasetAug(torch.utils.data.Dataset):\n",
    "    \"\"\"Uses jsonl data to preprocess and serve \n",
    "    dictionary of multimodal tensors for model input.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path,\n",
    "        img_dir,\n",
    "        mode=None,\n",
    "#         image_transform,\n",
    "#         text_transform,\n",
    "        balance=False,\n",
    "        dev_limit=None,\n",
    "        random_state=0,\n",
    "    ):\n",
    "        self.mode = mode\n",
    "\n",
    "        # self.samples_frame = pd.read_json(\n",
    "        #     data_path, lines=True\n",
    "        self.samples_frame = pd.read_csv(\n",
    "                data_path, index_col=0\n",
    "            )\n",
    "     \n",
    "\n",
    "        self.samples_frame = self.samples_frame.reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "        \n",
    "        # print(self.samples_frame.head())\n",
    "        self.samples_frame.image = self.samples_frame.apply(\n",
    "            lambda row: (img_dir + '/' + row.image), axis=1\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"This method is called when you do len(instance) \n",
    "        for an instance of this class.\n",
    "        \"\"\"\n",
    "        return len(self.samples_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"This method is called when you do instance[key] \n",
    "        for an instance of this class.\n",
    "        \"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # img_id = self.samples_frame.loc[idx, \"id\"]\n",
    "        img_name = self.samples_frame.loc[idx, \"image\"]  \n",
    "        # print(f'img_name: {img_name}')\n",
    "\n",
    "    \n",
    "#         ***Get VIT input data***\n",
    "        file_name = self.samples_frame.loc[idx, \"image\"]\n",
    "        vit_image_data = Image.open(file_name)\n",
    "        if vit_image_data.mode != 'RGB':\n",
    "            vit_image_data = vit_image_data.convert('RGB')  \n",
    "        vit_image_data = feature_extractor(vit_image_data, return_tensors=\"pt\")\n",
    "        \n",
    "        \n",
    "        ocr = self.samples_frame.loc[idx, \"OCR\"]\n",
    "        ent = self.samples_frame.loc[idx, \"entity\"]\n",
    "        role = self.samples_frame.loc[idx, \"role\"]\n",
    "        caption = self.samples_frame.loc[idx, \"caption\"]\n",
    "        \n",
    "        bert_inputs_ocr = ocr\n",
    "        bert_inputs_ent = ent\n",
    "        \n",
    "        \n",
    "        bert_inputs = [bert_inputs_ocr, bert_inputs_ent]\n",
    "        \n",
    "               \n",
    "        \n",
    "        # ---------------------------------------------\n",
    "        # T5 douple scenario: prompt input + caption\n",
    "        T5_source1 = \"Generate explanation for \"+ent+\" as \"+role+\": \"+ocr.replace('\\n', ' ').replace(' .', '.')\n",
    "        T5_source2 = caption\n",
    "       \n",
    "        \n",
    "        if self.mode != 'test':\n",
    "            T5_target = self.samples_frame.loc[idx, \"explanation\"]\n",
    "        else:\n",
    "            T5_target = self.samples_frame.loc[idx, \"siddhant's explanations\"]\n",
    "        if self.samples_frame.loc[idx, \"role\"]==\"hero\":\n",
    "            lab=0\n",
    "        elif self.samples_frame.loc[idx, \"role\"]==\"victim\":\n",
    "            lab=1     \n",
    "        else:\n",
    "            lab=2\n",
    "        label = torch.tensor(lab).to(device)  \n",
    "\n",
    "        sample = {\n",
    "            # \"id\": img_id, \n",
    "            \"img_name\": img_name,                \n",
    "            \"bert_inputs\": bert_inputs,\n",
    "            # \"inputs_ocr\": bert_inputs_ocr,\n",
    "            # \"inputs_entity\": bert_inputs_ent,\n",
    "            \"vit_image_data\": vit_image_data,\n",
    "            # \"det_img_bgr\": img_bgr,\n",
    "            \"label\": label,\n",
    "            \"T5_source1\": T5_source1,\n",
    "            \"T5_source2\": T5_source2,\n",
    "            \"T5_target\": T5_target\n",
    "        }\n",
    "        return sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# In[28]:\n",
    "\n",
    "\n",
    "BS = 4 #at least 10 can be tried (12327MiB being used)\n",
    "\n",
    "hm_dataset_train = HarmemeMemesDatasetAug(train_path, data_dir)\n",
    "dataloader_train = DataLoader(hm_dataset_train, batch_size=BS,\n",
    "                        shuffle=True, num_workers=0)\n",
    "hm_dataset_val = HarmemeMemesDatasetAug(dev_path, data_dir)\n",
    "dataloader_val = DataLoader(hm_dataset_val, batch_size=BS,\n",
    "                        shuffle=True, num_workers=0)\n",
    "hm_dataset_test = HarmemeMemesDatasetAug(test_path, data_dir, mode='test')\n",
    "dataloader_test = DataLoader(hm_dataset_test, batch_size=BS,\n",
    "                        shuffle=False, num_workers=0)\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "data_time = AverageMeter('Data', ':6.3f')\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "class MM(nn.Module):\n",
    "    def __init__(self, n_out):\n",
    "        super(MM, self).__init__()               \n",
    "        self.model_ViT = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "        self.model_deBERTa = DebertaV2ForSequenceClassification.from_pretrained(\"microsoft/deberta-v2-xlarge\", num_labels=n_out, problem_type=\"multi_label_classification\", output_hidden_states=True)\n",
    "        self.model_T5 = T5ForConditionalGeneration.from_pretrained(\"t5-large\")\n",
    "        \n",
    "        self.trans1 = nn.Linear(768,512)\n",
    "        self.trans2 = nn.Linear(1536,512)\n",
    "        self.trans3 = nn.Linear(1024,512)        \n",
    "        \n",
    "        self.lin1 = nn.Linear(1536,512)\n",
    "        self.out = nn.Linear(512,n_out)\n",
    "        \n",
    "    # vit_inputs, deBERTainputs, deBERTalabels, T5input_ids, T5attention_mask, T5labels\n",
    "    def forward(self, vit_inputs, dinputs, dlabels, T5input_ids, T5attention_mask, T5labels):\n",
    "        # print(\"inside the forward loop\")\n",
    "        vit_output = self.model_ViT(vit_inputs)\n",
    "        vit_pooled_out = vit_output.pooler_output\n",
    "        \n",
    "        deBERTa_output = self.model_deBERTa(**dinputs, labels=dlabels)\n",
    "        deBERTa_lasthid = deBERTa_output.hidden_states[-1]\n",
    "        deBERTa_pooled_out = torch.mean(deBERTa_lasthid, 1)\n",
    "        \n",
    "        T5_output = self.model_T5(input_ids=T5input_ids, attention_mask=T5attention_mask, labels=T5labels, output_hidden_states=True, return_dict=True)\n",
    "        T5_lasthid = T5_output.decoder_hidden_states[-1]\n",
    "        T5_pooled_out = torch.mean(T5_lasthid, 1)\n",
    "        \n",
    "        # Transform\n",
    "        vit_mm = F.relu(self.trans1(vit_pooled_out))\n",
    "        dberta_mm = F.relu(self.trans2(deBERTa_pooled_out))\n",
    "        t5_mm = F.relu(self.trans3(T5_pooled_out))\n",
    "        \n",
    "        # Additional components        \n",
    "        \n",
    "        # vbert_pooled_out = torch.mean(vbert_encoder_lasthid, 1)\n",
    "        fused_out = torch.cat([vit_mm, dberta_mm, t5_mm], axis=1)\n",
    "        out1 = F.relu(self.lin1(fused_out))\n",
    "        out = self.out(out1)\n",
    "        return T5_output, out, deBERTa_output.loss\n",
    "# ----------------------------------------------\n",
    "# Can comment out the following to run separately\n",
    "\n",
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "# output_size = 1 #Binary case\n",
    "output_size = 3\n",
    "model = MM(output_size)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "code_prof = False\n",
    "\n",
    "exp_name = \"name-of-experiment\"\n",
    "exp_path = \"/path-to-saved-model/\"+exp_name\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# replace AdamW with Adafactor\n",
    "optimizer = Adafactor(\n",
    "    model.parameters(),\n",
    "    lr=1e-4,\n",
    "    eps=(1e-30, 1e-3),\n",
    "    clip_threshold=1.0,\n",
    "    decay_rate=-0.8,\n",
    "    beta1=None,\n",
    "    weight_decay=0.0,\n",
    "    relative_step=False,\n",
    "    scale_parameter=False,\n",
    "    warmup_init=False,\n",
    ")\n",
    "\n",
    "\n",
    "max_source_length = 512\n",
    "max_target_length = 512\n",
    "\n",
    "# For cross entropy loss\n",
    "def train_model(model, patience, n_epochs):\n",
    "    epochs = n_epochs\n",
    "#     clip = 5\n",
    "    \n",
    "    train_acc_list=[]\n",
    "    val_acc_list=[]\n",
    "    train_loss_list=[]\n",
    "    val_loss_list=[]\n",
    "    train_T5encdec_loss_list=[]\n",
    "    val_T5encdec_loss_list=[]\n",
    "    train_main_loss_list=[]\n",
    "    val_main_loss_list=[]\n",
    "    train_deBERTa_loss_list=[]\n",
    "    val_deBERTa_loss_list=[]\n",
    "    \n",
    "        # initialize the experiment path\n",
    "    Path(exp_path).mkdir(parents=True, exist_ok=True)\n",
    "    # initialize early_stopping object\n",
    "    chk_file = os.path.join(exp_path, 'checkpoint_'+exp_name+'.pt')\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True, path=chk_file)\n",
    "    \n",
    "\n",
    "    model.train()\n",
    "    for i in range(epochs):\n",
    "        # print(f\"******************************EPOCH - {i}****************************************\")\n",
    "#         total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "        total_T5encdec_loss_train = 0\n",
    "        total_main_loss_train = 0\n",
    "        total_deBERTa_loss_train = 0\n",
    "        total_train = 0\n",
    "        correct_train = 0\n",
    "        # for data in dataloader_train:\n",
    "        for data in tqdm(dataloader_train, total = len(dataloader_train), desc = f\"Mini-batch progress (Train) | Epoch: {i+1}\"):\n",
    "            # print(f'------------------Mini Batch - {mbcnt+1}------------------')\n",
    "            # mbcnt+=1\n",
    "            \n",
    "            \n",
    "            \n",
    "            pixel_values_start = time.time()\n",
    "            vit_inputs = data['vit_image_data'].pixel_values.squeeze().to(device)\n",
    "            data_time.update(time.time() - pixel_values_start)\n",
    "            if code_prof:\n",
    "                print(f\"vision_inputs processing time: {data_time.val}\")\n",
    "                \n",
    "                \n",
    "            # deBERTa inputs\n",
    "            deBERTainputs = deBERTatokenizer(data['bert_inputs'][0], data['bert_inputs'][1], padding=True, return_tensors=\"pt\").to(device)\n",
    "            deBERTalabels = torch.nn.functional.one_hot(data['label'],num_classes=3).to(torch.float).to(device)\n",
    "            \n",
    "\n",
    "            data_time.reset()\n",
    "            decoder_labels_start = time.time()\n",
    "            \n",
    "            T5encoding = T5tokenizer(\n",
    "                data['T5_source1'],\n",
    "                data['T5_source2'],\n",
    "                padding=\"longest\",\n",
    "                max_length=max_source_length,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "            ).to(device)\n",
    "            T5input_ids, T5attention_mask = T5encoding.input_ids, T5encoding.attention_mask\n",
    "            \n",
    "            # encode the targets\n",
    "            T5target_encoding = T5tokenizer(\n",
    "                data['T5_target'], padding=\"longest\", max_length=max_target_length, truncation=True\n",
    "            )\n",
    "            \n",
    "            T5labels = T5target_encoding.input_ids\n",
    "            # replace padding token id's of the labels by -100 so it's ignored by the loss\n",
    "            T5labels = torch.tensor(T5labels).to(device)\n",
    "            T5labels[T5labels == T5tokenizer.pad_token_id] = -100\n",
    "            if code_prof:\n",
    "                print(f\"T5 input processing time: {data_time.val}\")\n",
    "            \n",
    "            label = data['label'].to(device)\n",
    "            \n",
    "            model.zero_grad()\n",
    "            data_time.reset()\n",
    "            model_start = time.time()\n",
    "            \n",
    "            T5encdec_out, main_out, deBERTa_loss = model(vit_inputs, deBERTainputs, deBERTalabels, T5input_ids, T5attention_mask, T5labels)\n",
    "            data_time.update(time.time() - model_start)\n",
    "            if code_prof:\n",
    "                print(f\"model processing time: {data_time.val}\")\n",
    "            # print(vencdec_out.decoder_hidden_states[-1].shape)\n",
    "            T5encdec_loss = T5encdec_out.loss\n",
    "            main_loss = criterion(main_out.squeeze(), label)\n",
    "            # print(main_loss)\n",
    "            loss = 0.5*T5encdec_loss+0.3*main_loss+0.2*deBERTa_loss\n",
    "            # print(f\"vencdec_loss: {vencdec_loss.item()} | main_loss: {main_loss.item() | Total loss: {loss.item()}}\")\n",
    "            loss.backward()\n",
    "            optimizer.step()            \n",
    "            # print(main_out.data)\n",
    "            with torch.no_grad():\n",
    "                # print(torch.max(main_out.data, 1))\n",
    "                _, predicted_train = torch.max(main_out.data, 1)\n",
    "                total_train += label.size(0)\n",
    "                correct_train += (predicted_train == label).sum().item()\n",
    "                total_T5encdec_loss_train += T5encdec_loss.item()\n",
    "                total_main_loss_train += main_loss.item()\n",
    "                total_deBERTa_loss_train += deBERTa_loss.item()\n",
    "                total_loss_train += loss.item()\n",
    "            # break\n",
    "\n",
    "        # break\n",
    "        train_acc = 100 * correct_train / total_train\n",
    "        train_loss = total_loss_train/total_train\n",
    "        train_T5encdec_loss = total_T5encdec_loss_train/total_train\n",
    "        train_main_loss = total_main_loss_train/total_train\n",
    "        train_deBERTa_loss = total_deBERTa_loss_train/total_train\n",
    "        model.eval()\n",
    "#         total_acc_val = 0\n",
    "        total_loss_val = 0\n",
    "        total_T5encdec_loss_val = 0\n",
    "        total_main_loss_val = 0\n",
    "        total_deBERTa_loss_val = 0\n",
    "        total_val = 0\n",
    "        correct_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in tqdm(dataloader_val, total = len(dataloader_val), desc = \"Mini-batch progress (Val)\"):               \n",
    "                pixel_values_start = time.time()\n",
    "                vit_inputs = data['vit_image_data'].pixel_values.squeeze().to(device)\n",
    "                data_time.update(time.time() - pixel_values_start)\n",
    "                if code_prof:\n",
    "                    print(f\"vision_inputs processing time: {data_time.val}\")\n",
    "\n",
    "\n",
    "                # deBERTa inputs\n",
    "                deBERTainputs = deBERTatokenizer(data['bert_inputs'][0], data['bert_inputs'][1], padding=True, return_tensors=\"pt\").to(device)\n",
    "                deBERTalabels = torch.nn.functional.one_hot(data['label'],num_classes=3).to(torch.float).to(device)\n",
    "\n",
    "\n",
    "                data_time.reset()\n",
    "                decoder_labels_start = time.time()\n",
    "                T5encoding = T5tokenizer(\n",
    "                    data['T5_source1'],\n",
    "                    data['T5_source2'],\n",
    "                    padding=\"longest\",\n",
    "                    max_length=max_source_length,\n",
    "                    truncation=True,\n",
    "                    return_tensors=\"pt\",\n",
    "                ).to(device)\n",
    "                T5input_ids, T5attention_mask = T5encoding.input_ids, T5encoding.attention_mask\n",
    "\n",
    "                # encode the targets\n",
    "                T5target_encoding = T5tokenizer(\n",
    "                    data['T5_target'], padding=\"longest\", max_length=max_target_length, truncation=True\n",
    "                )\n",
    "\n",
    "                T5labels = T5target_encoding.input_ids\n",
    "                # replace padding token id's of the labels by -100 so it's ignored by the loss\n",
    "                T5labels = torch.tensor(T5labels).to(device)\n",
    "                T5labels[T5labels == T5tokenizer.pad_token_id] = -100\n",
    "                if code_prof:\n",
    "                    print(f\"T5 input processing time: {data_time.val}\")\n",
    "\n",
    "                label_val = data['label'].to(device)\n",
    "                model.zero_grad()\n",
    "                data_time.reset()\n",
    "                model_start = time.time()\n",
    "                T5encdec_out_val, main_out_val, deBERTa_loss_val = model(vit_inputs, deBERTainputs, deBERTalabels, T5input_ids, T5attention_mask, T5labels)\n",
    "                data_time.update(time.time() - model_start)\n",
    "                if code_prof:\n",
    "                    print(f\"model processing time: {data_time.val}\")\n",
    "                # print(main_out_val.squeeze())\n",
    "                T5encdec_loss_val = T5encdec_out_val.loss\n",
    "                main_loss_val = criterion(main_out_val.squeeze(), label_val)\n",
    "                # print(main_loss_val)\n",
    "                loss_val = 0.5*T5encdec_loss_val+0.3*main_loss_val+0.2*deBERTa_loss_val\n",
    "                \n",
    "                \n",
    "                _, predicted_val = torch.max(main_out_val.data, 1)\n",
    "                total_val += label_val.size(0)\n",
    "                correct_val += (predicted_val == label_val).sum().item()                \n",
    "                total_T5encdec_loss_val += T5encdec_loss_val.item()\n",
    "                total_main_loss_val += main_loss_val.item()\n",
    "                total_deBERTa_loss_val += deBERTa_loss_val.item()\n",
    "                total_loss_val += loss_val.item()\n",
    "                                \n",
    "                \n",
    "        print(\"Saving model...\") \n",
    "        torch.save(model.state_dict(), os.path.join(exp_path, \"final.pt\"))\n",
    "\n",
    "        val_acc = 100 * correct_val / total_val\n",
    "        val_loss = total_loss_val/total_val\n",
    "        val_T5encdec_loss = total_T5encdec_loss_val/total_val\n",
    "        val_main_loss = total_main_loss_val/total_val\n",
    "        val_deBERTa_loss = total_deBERTa_loss_val/total_val\n",
    "        \n",
    "        \n",
    "        \n",
    "        train_acc_list.append(train_acc)\n",
    "        val_acc_list.append(val_acc)\n",
    "        train_loss_list.append(train_loss)\n",
    "        val_loss_list.append(val_loss)\n",
    "        train_T5encdec_loss_list.append(train_T5encdec_loss)\n",
    "        val_T5encdec_loss_list.append(val_T5encdec_loss)\n",
    "        train_main_loss_list.append(train_main_loss)\n",
    "        val_main_loss_list.append(val_main_loss)\n",
    "        train_deBERTa_loss_list.append(train_deBERTa_loss)\n",
    "        val_deBERTa_loss_list.append(val_deBERTa_loss)\n",
    "        \n",
    "        early_stopping(val_loss, model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "            \n",
    "        print(f'Epoch {i+1}: train_acc: {train_acc:.4f} | val_acc: {val_acc:.4f} | train_loss: {train_loss:.4f} | val_loss: {val_loss:.4f} | train_T5encdec_loss: {train_T5encdec_loss:.4f} | val_T5encdec_loss: {val_T5encdec_loss:.4f} | train_main_loss: {train_main_loss:.4f} | val_main_loss: {val_main_loss:.4f} | train_deBERTa_loss: {train_deBERTa_loss:.4f} | val_deBERTa_loss: {val_deBERTa_loss:.4f}')\n",
    "        with open(os.path.join(exp_path, exp_name+'_base_exp_results.txt'), 'a+') as of:\n",
    "            of.write(f'Epoch {i+1}: train_acc: {train_acc:.4f} | val_acc: {val_acc:.4f} | train_loss: {train_loss:.4f} | val_loss: {val_loss:.4f} | train_T5encdec_loss: {train_T5encdec_loss:.4f} | val_T5encdec_loss: {val_T5encdec_loss:.4f} | train_main_loss: {train_main_loss:.4f} | val_main_loss: {val_main_loss:.4f} | train_deBERTa_loss: {train_deBERTa_loss:.4f} | val_deBERTa_loss: {val_deBERTa_loss:.4f}\\n')\n",
    "        \n",
    "        model.train()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    return  model, train_acc_list, val_acc_list, train_loss_list, val_loss_list, train_T5encdec_loss_list, val_T5encdec_loss_list, train_main_loss_list, val_main_loss_list, train_deBERTa_loss, val_deBERTa_loss, i\n",
    "        \n",
    "\n",
    "    \n",
    "train = False\n",
    "\n",
    "if train:\n",
    "    n_epochs = 15\n",
    "    # early stopping patience; how long to wait after last time validation loss improved.\n",
    "    patience = 15\n",
    "    model, train_acc_list, val_acc_list, train_loss_list, val_loss_list, train_T5encdec_loss_list, val_T5encdec_loss_list, train_main_loss_list, val_main_loss_list, train_deBERTa_loss, val_deBERTa_loss, i = train_model(model, patience, n_epochs)\n",
    "\n",
    "\n",
    "# For T5 based model\n",
    "def test_model(model):\n",
    "    model.eval()\n",
    "    code_prof = False\n",
    "#         total_acc_val = 0\n",
    "    total_loss_test = 0\n",
    "    total_vencdec_loss_test = 0\n",
    "    total_main_loss_test = 0\n",
    "    total_deBERTa_loss_test = 0\n",
    "    total_test = 0\n",
    "    correct_test = 0\n",
    "    generated_result = []\n",
    "    predicted_label_list = []\n",
    "    true_label_list = []\n",
    "    img_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # for data in dataloader_test:  \n",
    "        for data in tqdm(dataloader_test, total = len(dataloader_test), desc = \"Mini-batch progress (Test)\"):  \n",
    "            cur_imgs = [x.split('/')[-1] for x in data['img_name']]\n",
    "            img_list+=cur_imgs\n",
    "            # print(cur_imgs)\n",
    "            pixel_values_start = time.time()\n",
    "            if len(data['vit_image_data'].pixel_values.squeeze().size())<BS:\n",
    "                # print(data['vit_image_data'].pixel_values.squeeze(0).shape)\n",
    "                vit_inputs = data['vit_image_data'].pixel_values.squeeze(0).to(device)\n",
    "            else:\n",
    "                vit_inputs = data['vit_image_data'].pixel_values.squeeze().to(device)\n",
    "            # print(vit_inputs.shape)\n",
    "            data_time.update(time.time() - pixel_values_start)\n",
    "            if code_prof:\n",
    "                print(f\"pixel_values processing time: {data_time.val}\")\n",
    "\n",
    "            # deBERTa inputs\n",
    "            deBERTainputs = deBERTatokenizer(data['bert_inputs'][0], data['bert_inputs'][1], padding=True, return_tensors=\"pt\").to(device)\n",
    "            deBERTalabels = torch.nn.functional.one_hot(data['label'],num_classes=3).to(torch.float).to(device)\n",
    "\n",
    "            data_time.reset()\n",
    "            decoder_labels_start = time.time()\n",
    "            T5encoding = T5tokenizer(\n",
    "                data['T5_source1'],\n",
    "                data['T5_source2'],\n",
    "                padding=\"longest\",\n",
    "                max_length=max_source_length,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "            ).to(device)\n",
    "            T5input_ids, T5attention_mask = T5encoding.input_ids, T5encoding.attention_mask\n",
    "\n",
    "            # encode the targets\n",
    "            T5target_encoding = T5tokenizer(\n",
    "                data['T5_target'], padding=\"longest\", max_length=max_target_length, truncation=True\n",
    "            )\n",
    "\n",
    "            T5labels = T5target_encoding.input_ids\n",
    "            # replace padding token id's of the labels by -100 so it's ignored by the loss\n",
    "            T5labels = torch.tensor(T5labels).to(device)\n",
    "            T5labels[T5labels == T5tokenizer.pad_token_id] = -100\n",
    "            if code_prof:\n",
    "                print(f\"T5 input processing time: {data_time.val}\")\n",
    "\n",
    "            label_test = data['label'].to(device)\n",
    "            # print(data['label'].detach().cpu().numpy())\n",
    "            true_label_list+=list(data['label'].detach().cpu().numpy())\n",
    "            model.zero_grad()\n",
    "            data_time.reset()\n",
    "            model_start = time.time()\n",
    "            \n",
    "            vencdec_out_test, main_out_test, deBERTa_loss_test = model(vit_inputs, deBERTainputs, deBERTalabels, T5input_ids, T5attention_mask, T5labels)\n",
    "            data_time.update(time.time() - model_start)\n",
    "            if code_prof:\n",
    "                print(f\"model processing time: {data_time.val}\")\n",
    "            \n",
    "            # print(main_out_val.squeeze())\n",
    "            vencdec_loss_test = vencdec_out_test.loss\n",
    "            \n",
    "            try:\n",
    "                main_loss_test = criterion(main_out_test.squeeze(), label_test)\n",
    "            except:\n",
    "                print(main_out_test.squeeze)\n",
    "                print(label_test)\n",
    "                main_loss_test = criterion(main_out_test, label_test)\n",
    "            # print(main_loss_val)\n",
    "            loss_test = 0.5*vencdec_loss_test+0.3*main_loss_test+0.2*deBERTa_loss_test\n",
    "            # print(f\"val_vencdec_loss: {vencdec_loss_val.item()} | val_main_loss: {main_loss_val.item() | Total VAL loss: {loss_val.item()}}\")\n",
    "\n",
    "            _, predicted_test = torch.max(main_out_test.data, 1)\n",
    "            predicted_test_cur = list(predicted_test.detach().cpu().numpy())\n",
    "            predicted_label_list+=list(predicted_test_cur)\n",
    "            # print(label_test.size(0))\n",
    "            total_test += label_test.size(0)\n",
    "            correct_test += (predicted_test == label_test).sum().item()                \n",
    "            total_vencdec_loss_test += vencdec_loss_test.item()\n",
    "            total_main_loss_test += main_loss_test.item()\n",
    "            total_deBERTa_loss_test += deBERTa_loss_test.item()\n",
    "            total_loss_test += loss_test.item()\n",
    "            \n",
    "                        \n",
    "            output_sequences = model.model_T5.generate(input_ids=T5input_ids,attention_mask=T5attention_mask,do_sample=False, min_length= 0, max_length=512)\n",
    "            generated_text = T5tokenizer.batch_decode(output_sequences, skip_special_tokens=True)\n",
    "            generated_result+=generated_text\n",
    "            # break\n",
    "   \n",
    "\n",
    "    test_acc = 100 * correct_test / total_test\n",
    "    test_loss = total_loss_test/total_test\n",
    "    test_vencdec_loss = total_vencdec_loss_test/total_test\n",
    "    test_main_loss = total_main_loss_test/total_test\n",
    "    test_deBERTa_loss = total_deBERTa_loss_test/total_test\n",
    "    \n",
    "    return  test_acc, test_loss, test_vencdec_loss, test_main_loss, test_deBERTa_loss, generated_result, true_label_list, predicted_label_list, img_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "mode = ''\n",
    "for i in range(2):\n",
    "    test_df = pd.read_csv(test_path, index_col=0)\n",
    "    if i == 1:\n",
    "        mode = '_bestckp'  \n",
    "        try:\n",
    "            del model\n",
    "        except:\n",
    "            pass\n",
    "        path = os.path.join(exp_path, 'checkpoint_'+exp_name+'.pt')        \n",
    "        n_out=3\n",
    "        model = MM(n_out)\n",
    "        model.load_state_dict(torch.load(path))\n",
    "        model.to(device)\n",
    "    else:\n",
    "        mode = ''  \n",
    "        try:\n",
    "            del model\n",
    "        except:\n",
    "            pass\n",
    "        path = os.path.join(exp_path, \"final.pt\")\n",
    "        n_out=3\n",
    "        model = MM(n_out)\n",
    "        model.load_state_dict(torch.load(path))\n",
    "        model.to(device)\n",
    "        \n",
    "    test_acc, test_loss, test_vencdec_loss, test_main_loss, test_deBERTa_loss, generated_result, true_label_list, predicted_label_list, img_list = test_model(model)\n",
    "    if i==0:\n",
    "        print('---Last checkpoint results---')\n",
    "    else:\n",
    "        print('---Best checkpoint results---')\n",
    "    print(\"test_acc, test_loss, test_vencdec_loss, test_main_loss, test_deBERTa_loss\")\n",
    "    print(test_acc, test_loss, test_vencdec_loss, test_main_loss, test_deBERTa_loss)\n",
    "    print(classification_report(true_label_list, predicted_label_list, target_names=['Hero', 'Victim', 'Villain']))\n",
    "    print(f\"generated sequences: {len(generated_result)}\")\n",
    "    # generated_result\n",
    "    \n",
    "    resdf = pd.DataFrame.from_dict({'images': img_list, 'generated_result': generated_result})\n",
    "    sid_list = test_df[\"siddhant's explanations\"].tolist()\n",
    "    tharun_list = test_df[\"tharun's explanations\"].tolist()\n",
    "    resdf['sid_exp'] = sid_list\n",
    "    resdf['tharun_exp'] = tharun_list\n",
    "    resdf.to_csv(os.path.join(exp_path, exp_name+'_GenTrue_exp'+mode+'.csv'), index=False)\n",
    "    with open(os.path.join(exp_path, 'hyp'+mode+'.txt'), 'w+') as hf:\n",
    "        hf.write('\\n'.join(generated_result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FACT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
